{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_CNN(audio_dir, spectrogram_dir):\n",
    "  file_names = []\n",
    "  for audio_subdir in os.walk(audio_dir):\n",
    "      file_names += [join(audio_subdir[0], f) for f in listdir(audio_subdir[0]) if isfile(join(audio_subdir[0], f)) and '.wav' in f]\n",
    "  for file_name in file_names:\n",
    "    print(file_name)\n",
    "    audio_path =  file_name\n",
    "    spectogram_path = spectrogram_dir + file_name.split(\"/\")[2].replace('.wav', '.png')\n",
    "    wav_to_spectrogram(audio_path, spectogram_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e04d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_spectrogram(audio_path, save_path):\n",
    "  spectrogram_dimensions=(64, 64)\n",
    "  sample_rate, samples = wav.read(audio_path)\n",
    "  fig = plt.figure()\n",
    "  fig.set_size_inches((spectrogram_dimensions[0]/fig.get_dpi(), spectrogram_dimensions[1]/fig.get_dpi()))\n",
    "  ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "  ax.set_axis_off()\n",
    "  fig.add_axes(ax)\n",
    "  ax.specgram(samples, cmap='gray_r', Fs=2, noverlap=16)\n",
    "  ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "  ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "  fig.savefig(save_path, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef25f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = \"data/\"\n",
    "spectrogram_folder = \"spectrograms/\"\n",
    "os.makedirs(spectrogram_folder, exist_ok=True)\n",
    "preprocess_data_CNN(audio_folder, spectrogram_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "imagesDir = \"spectrograms/\"\n",
    "trainset = []\n",
    "testset = []\n",
    "for file in os.listdir(imagesDir):\n",
    "  if file != \".ipynb_checkpoints\":\n",
    "    label = file.split('_')[0]\n",
    "    sample_number = file.split('_')[2]\n",
    "    img = tf.keras.utils.load_img(imagesDir+file)\n",
    "#     print(img)\n",
    "    if sample_number in ['1.','3.','5.','7.','9.']:\n",
    "      testset.append([tf.keras.utils.img_to_array(img), label])\n",
    "    else:\n",
    "      trainset.append([tf.keras.utils.img_to_array(img), label])\n",
    "\n",
    "    \n",
    "X_train = [item[0] for item in trainset]\n",
    "Y_train = [item[1] for item in trainset]\n",
    "X_test = [item[0] for item in testset]\n",
    "Y_test = [item[1] for item in testset]\n",
    "\n",
    "X_train = np.asanyarray(X_train)\n",
    "X_test = np.asanyarray(X_test)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np.asanyarray(Y_train)\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = np.asanyarray(Y_test)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "data_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "def basic_cnn():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=data_shape))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "  return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN = basic_cnn()\n",
    "history = model_CNN.fit(X_train, Y_train, batch_size = 50, validation_split=0.2, epochs = 50, verbose = 1)\n",
    "model_CNN.evaluate(X_test,Y_test)\n",
    "model_CNN.save(\"model_CNN.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"Train\",\"Validation\"], loc=\"upper left\")\n",
    "# plt.savefig(\"acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"Train\",\"Validation\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "# plt.savefig(\"los.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
